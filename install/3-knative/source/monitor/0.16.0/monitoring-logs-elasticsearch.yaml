apiVersion: v1
kind: Service
metadata:
  name: elasticsearch-logging
  namespace: knative-monitoring
  labels:
    app: elasticsearch-logging
    kubernetes.io/cluster-service: "true"
    kubernetes.io/name: "Elasticsearch"
spec:
  ports:
  - port: 9200
    protocol: TCP
    targetPort: db
  selector:
    app: elasticsearch-logging
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: elasticsearch-logging
  namespace: knative-monitoring
  labels:
    app: elasticsearch-logging
    kubernetes.io/cluster-service: "true"
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: elasticsearch-logging
  labels:
    app: elasticsearch-logging
    kubernetes.io/cluster-service: "true"
rules:
- apiGroups:
  - ""
  resources:
  - "services"
  - "namespaces"
  - "endpoints"
  verbs:
  - "get"
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: knative-monitoring
  name: elasticsearch-logging
  labels:
    app: elasticsearch-logging
    kubernetes.io/cluster-service: "true"
subjects:
- kind: ServiceAccount
  name: elasticsearch-logging
  namespace: knative-monitoring
  apiGroup: ""
roleRef:
  kind: ClusterRole
  name: elasticsearch-logging
  apiGroup: ""
---
# Elasticsearch deployment itself
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch-logging
  namespace: knative-monitoring
  labels:
    app: elasticsearch-logging
    version: v5.6.4
    kubernetes.io/cluster-service: "true"
spec:
  serviceName: elasticsearch-logging
  replicas: 2
  selector:
    matchLabels:
      app: elasticsearch-logging
      version: v5.6.4
  template:
    metadata:
      labels:
        app: elasticsearch-logging
        version: v5.6.4
        kubernetes.io/cluster-service: "true"
    spec:
      serviceAccountName: elasticsearch-logging
      containers:
      - image: k8s.gcr.io/elasticsearch:v5.6.4
        name: elasticsearch-logging
        resources:
          limits:
            cpu: 1000m
          requests:
            cpu: 100m
        ports:
        - containerPort: 9200
          name: db
          protocol: TCP
        - containerPort: 9300
          name: transport
          protocol: TCP
        volumeMounts:
        - name: elasticsearch-logging
          mountPath: /data
        env:
        - name: "NAMESPACE"
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
      volumes:
      - name: elasticsearch-logging
        emptyDir: {}
      # Elasticsearch requires vm.max_map_count to be at least 262144.
      # If your OS already sets up this number to a higher value, feel free
      # to remove this init container.
      initContainers:
      - image: alpine:3.6
        command: ["/sbin/sysctl", "-w", "vm.max_map_count=262144"]
        name: elasticsearch-logging-init
        securityContext:
          privileged: true

---
apiVersion: v1
kind: Service
metadata:
  name: kibana-logging
  namespace: knative-monitoring
  labels:
    app: kibana-logging
    kubernetes.io/cluster-service: "true"
    kubernetes.io/name: "Kibana"
spec:
  selector:
    app: kibana-logging
  ports:
  - port: 5601
    protocol: TCP
    targetPort: ui
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kibana-logging
  namespace: knative-monitoring
  labels:
    app: kibana-logging
    kubernetes.io/cluster-service: "true"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kibana-logging
  template:
    metadata:
      labels:
        app: kibana-logging
    spec:
      containers:
      - name: kibana-logging
        image: docker.elastic.co/kibana/kibana:5.6.4
        resources:
          limits:
            cpu: 1000m
          requests:
            cpu: 100m
        env:
        - name: ELASTICSEARCH_URL
          value: http://elasticsearch-logging:9200
          # If you want to access Kibana through NodePort or LoadBalancer outside the cluster,
          # you should remove the SERVER_BASEPATH env
        - name: SERVER_BASEPATH
          value: /api/v1/namespaces/knative-monitoring/services/kibana-logging/proxy
        - name: XPACK_MONITORING_ENABLED
          value: "false"
        - name: XPACK_SECURITY_ENABLED
          value: "false"
        ports:
        - containerPort: 5601
          name: ui
          protocol: TCP

---
# Copyright 2018 The Knative Authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

kind: ConfigMap
apiVersion: v1
metadata:
  name: fluentd-ds-config
  namespace: knative-monitoring
  labels:
    serving.knative.dev/release: "v0.16.0"
data:
  100.system.conf: |-
    <system>
      root_dir /tmp/fluentd-buffers/
    </system>
  200.containers.input.conf: |-
    # Capture logs from container's stdout/stderr -> Docker -> .log in JSON format
    <source>
      @id containers-stdout-stderr
      @type tail
      path /var/log/containers/*user-container-*.log,/var/log/containers/*build-step-*.log,/var/log/containers/controller-*controller-*.log,/var/log/containers/webhook-*webhook-*.log,/var/log/containers/*autoscaler-*autoscaler-*.log,/var/log/containers/*queue-proxy-*.log,/var/log/containers/activator-*activator-*.log
      pos_file /var/log/containers-stdout-stderr.pos
      time_format %Y-%m-%dT%H:%M:%S.%NZ
      tag raw.kubernetes.*
      format json
      read_from_head true
    </source>
    # Capture logs from Knative containers' /var/log
    <source>
      @id containers-var-log
      @type tail
      # **/*/**/* allows path expansion to go through one symlink (the one created by the init container)
      path /var/lib/kubelet/pods/*/volumes/kubernetes.io~empty-dir/knative-var-log/**/*/**/*
      path_key stream
      pos_file /var/log/containers-var-log.pos
      tag raw.kubernetes.*
      message_key log
      read_from_head true
      <parse>
        @type multi_format
        <pattern>
          format json
          time_key fluentd-time # fluentd-time is reserved for structured logs
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </pattern>
        <pattern>
          format none
          message_key log
        </pattern>
      </parse>
    </source>
    # Combine multi line logs which form an exception stack trace into a single log entry
    <match raw.kubernetes.**>
      @id raw.kubernetes
      @type detect_exceptions
      remove_tag_prefix raw
      message log
      stream stream
      multiline_flush_interval 5
      max_bytes 500000
      max_lines 1000
    </match>
    # Make stream path correct from the container's point of view
    <filter kubernetes.var.lib.kubelet.pods.*.volumes.kubernetes.io~empty-dir.knative-var-log.*.**>
      @type record_transformer
      enable_ruby true
      <record>
        stream /var/log/${record["stream"].scan(/\/knative-var-log\/[^\/]+\/(.*)/).last.last}
      </record>
    </filter>
    # Add Kubernetes metadata to logs from /var/log/containers
    <filter kubernetes.var.log.containers.**>
      @type kubernetes_metadata
    </filter>
    # Add Kubernetes metadata to logs from /var/lib/kubelet/pods/*/volumes/kubernetes.io~empty-dir/knative-var-log/**/*/**/*
    <filter kubernetes.var.lib.kubelet.pods.**>
      @type kubernetes_metadata
      tag_to_kubernetes_name_regexp (?<docker_id>[a-z0-9]{8}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{12})\.volumes\.kubernetes\.io~empty-dir\.knative-var-log\.(?<namespace>[^_]+)_(?<pod_name>[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*)_(?<container_name>)[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*\..*?$
    </filter>
  300.forward.input.conf: |-
    # Takes the messages sent over TCP, e.g. request logs from Istio
    <source>
      @type forward
      port 24224
    </source>
  900.output.conf: |-
    # Send to Elastic Search
    <match **>
      @id elasticsearch
      @type elasticsearch
      @log_level info
      host elasticsearch-logging
      port 9200
      logstash_format true
      <buffer>
        @type file
        path /var/log/fluentd-buffers/kubernetes.system.buffer
        flush_mode interval
        retry_type exponential_backoff
        flush_thread_count 2
        flush_interval 5s
        retry_forever
        retry_max_interval 30
        chunk_limit_size 2M
        queue_limit_length 8
        overflow_action block
      </buffer>
    </match>

---
# Copyright 2018 The Knative Authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: v1
kind: ServiceAccount
metadata:
  name: fluentd-ds
  namespace: knative-monitoring
  labels:
    app: fluentd-ds
    serving.knative.dev/release: "v0.16.0"
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: fluentd-ds
  labels:
    app: fluentd-ds
    serving.knative.dev/release: "v0.16.0"
rules:
- apiGroups:
  - ""
  resources:
  - "namespaces"
  - "pods"
  verbs:
  - "get"
  - "watch"
  - "list"
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: fluentd-ds
  labels:
    app: fluentd-ds
    serving.knative.dev/release: "v0.16.0"
subjects:
- kind: ServiceAccount
  name: fluentd-ds
  namespace: knative-monitoring
  apiGroup: ""
roleRef:
  kind: ClusterRole
  name: fluentd-ds
  apiGroup: ""
---
apiVersion: v1
kind: Service
metadata:
  # Name of this service is referred at multiple places. 
  # Any changes to this name should ensure to fix it in
  # all places where this name is referred.
  name: fluentd-ds
  namespace: knative-monitoring
  labels:
    app: fluentd-ds
    serving.knative.dev/release: "v0.16.0"
spec:
  selector:
    app: fluentd-ds
  ports:
  - name: fluentd-tcp
    port: 24224
    protocol: TCP
    targetPort: 24224
  - name: fluentd-udp
    port: 24224
    protocol: UDP
    targetPort: 24224
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd-ds
  namespace: knative-monitoring
  labels:
    app: fluentd-ds
    version: v2.0.4
    serving.knative.dev/release: "v0.16.0"
spec:
  selector:
    matchLabels:
      app: fluentd-ds
      version: v2.0.4
  template:
    metadata:
      labels:
        app: fluentd-ds
        version: v2.0.4
        serving.knative.dev/release: "v0.16.0"
      # This annotation ensures that fluentd does not get evicted if the node
      # supports critical pod annotation based priority scheme.
      # Note that this does not guarantee admission on the nodes (#40573).
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      serviceAccountName: fluentd-ds
      containers:
      - name: fluentd-ds
        image: k8s.gcr.io/fluentd-elasticsearch:v2.0.4
        env:
        - name: FLUENTD_ARGS
          value: --no-supervisor -q
        resources:
          limits:
            memory: 500Mi
          requests:
            cpu: 100m
            memory: 200Mi
        volumeMounts:
        - name: varlogcontainers
          mountPath: /var/log/containers
          readOnly: true
        - name: varlogpods
          mountPath: /var/log/pods
          readOnly: true
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: varlibkubeletpods
          mountPath: /var/lib/kubelet/pods
          readOnly: true
        - name: libsystemddir
          mountPath: /host/lib
          readOnly: true
        - name: config-volume
          mountPath: /etc/fluent/config.d
      nodeSelector:
        beta.kubernetes.io/fluentd-ds-ready: "true"
      terminationGracePeriodSeconds: 30
      volumes:
      - name: varlogcontainers
        hostPath:
          path: /var/log/containers
      - # It is needed because files under /var/log/containers link to /var/log/pods
        name: varlogpods
        hostPath:
          path: /var/log/pods
      - # It is needed because files under /var/log/pods link to /var/lib/docker/containers
        name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - # It is needed because user-container's /var/log is located in /var/lib/kubelet/pods/*/volumes/
        name: varlibkubeletpods
        hostPath:
          path: /var/lib/kubelet/pods
      - # It is needed to copy systemd library to decompress journals
        name: libsystemddir
        hostPath:
          path: /usr/lib64
      - name: config-volume
        configMap:
          name: fluentd-ds-config

---
